# BATCH-GRADIENT-DESCENT
Batch gradient descent (BGD) is an optimization algorithm used in machine learning to train models. It's an iterative process that aims to find the minimum point (often called the minimum loss) of a cost function.
